{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mohammed alom R00144214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import svm\n",
    "from arabicDataPreprocess import prepareTrainData, prepareDevData, prepareTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the files from drive\n",
    "train_file = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data/MADAR-Corpus-26-train.tsv'\n",
    "dev_file = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data/MADAR-Corpus-26-dev.tsv'\n",
    "\n",
    "#train_file = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data/MADAR-Corpus-6-train.tsv'\n",
    "#dev_file = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data/MADAR-Corpus-6-dev.tsv'\n",
    "\n",
    "test_file = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data/test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files directory\n",
    "corpus = 'E:/MSc/NLP/Assignment1/Mohammed_Alom_R00144214/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSource, _, trainTarget, _ = prepareTrainData(corpus= corpus)\n",
    "devSource, devTarget = prepareDevData(corpus= corpus)\n",
    "testSource = prepareTestData(corpus= corpus)\n",
    "#print(len(testSource))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLabels = ['ALE', 'ALG', 'ALX', 'AMM', 'ASW', 'BAG', 'BAS', 'BEI', 'BEN',\n",
    "              'CAI', 'DAM', 'DOH', 'FES', 'JED', 'JER', 'KHA', 'MOS', 'MSA',\n",
    "              'MUS', 'RAB', 'RIY', 'SAL', 'SAN', 'SFX', 'TRI', 'TUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "_y_train = [targetLabels.index(target.replace(' ', '')) for target in trainTarget]\n",
    "_y_dev = [targetLabels.index(target.replace(' ', '')) for target in devTarget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating total vectors with range 2 to 5 ngram token counts\n",
    "countTotalVectors = CountVectorizer(analyzer='word',  min_df=1, ngram_range=(2, 5), max_df=0.95,encoding='utf-8', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the vectors for train, dev, and test\n",
    "X_train_counts = countTotalVectors.fit_transform(trainSource)\n",
    "X_dev_counts = countTotalVectors.transform(devSource)\n",
    "X_test_counts = countTotalVectors.transform(testSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute word counts and nornalize with term frequency\n",
    "tf_vector = TfidfTransformer(use_idf=False)\n",
    "X_train_tf = tf_vector.fit_transform(X_train_counts)\n",
    "X_dev_tf = tf_vector.transform(X_dev_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing term-frequency times inverse document-frequency\n",
    "tfidf_vector = TfidfTransformer(use_idf=True, smooth_idf=False, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_vector.fit_transform(X_train_counts)\n",
    "X_dev_tfidf = tfidf_vector.transform(X_dev_counts)\n",
    "X_test_tfidf = tfidf_vector.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.31).fit(X_train_tfidf, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perfomring the classification\n",
    "trainPrediction = clf.predict(X_train_tfidf)\n",
    "devPrediction = clf.predict(X_dev_tfidf)\n",
    "testPrediction = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{corpus}/result/run_test_np_01.P',encoding=\"utf8\", mode='w') as prediction:\n",
    "    for rs in testPrediction:\n",
    "        prediction.write(f'{rs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{corpus}/result/run_dev_np_01.P',encoding=\"utf8\", mode='w') as prediction:\n",
    "    for rs in devPrediction:\n",
    "        prediction.write(f'{rs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{corpus}/result/run_dev_np_01.G',encoding=\"utf8\", mode='w') as prediction:\n",
    "    for rs in devTarget:\n",
    "        prediction.write(f'{rs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{corpus}/result/run_dev_np_01.A',encoding=\"utf8\", mode='w') as prediction:\n",
    "    for src, target, pred in zip(devSource, devTarget, devPrediction):\n",
    "        prediction.write(f'{src} T:{target} P:{pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Model\n",
      "Training Accuracy:  92.12 %\n",
      "Testing Accuracy:  36.15 %\n"
     ]
    }
   ],
   "source": [
    "print('MultinomialNB Model')\n",
    "print('Training Accuracy: ',np.around(np.mean(trainPrediction == trainTarget)*100,2), '%')\n",
    "print('Testing Accuracy: ',np.around(np.mean(devPrediction == devTarget)*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB- it took quite very long time to calcualte\n",
    "#if you run MaltinomialBM then keep SVC model uncomment and vis-versa\n",
    "# SVC Model \n",
    "'''\n",
    "print('\\nSVC Model')\n",
    "clf = svm.SVC(kernel='linear', C=300, )\n",
    "clf.fit(X_train_tfidf, trainTarget)\n",
    "train_pred = clf.predict(X_train_tfidf)\n",
    "dev_pred = clf.predict(X_dev_tfidf)\n",
    "print('Training Accuracy: ',np.around(np.mean(trainPrediction == trainTarget)*100,2), '%')\n",
    "print('Testing Accuracy: ',np.around(np.mean(devPrediction == devTarget)*100,2), '%')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
